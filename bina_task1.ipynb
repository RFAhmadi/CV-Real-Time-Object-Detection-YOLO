{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "445fbce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "import torch\n",
    "import time\n",
    "import math\n",
    "from collections import defaultdict\n",
    "\n",
    "# --- Main Settings ---\n",
    "WEBCAM_INDEX = 0    # Default webcam is 0\n",
    "# CONFIDENCE_THRESHOLD = 0.5 # Initial confidence threshold\n",
    "WINDOW_NAME = \"YOLO Real-Time Object Detection\"\n",
    "FONT = cv2.FONT_HERSHEY_SIMPLEX\n",
    "FONT_SCALE = 0.7\n",
    "FONT_COLOR = (255, 255, 255)  # White\n",
    "BOX_COLOR = (0, 255, 0)      # Green\n",
    "BOX_THICKNESS = 2\n",
    "COUNT_COLOR = (0, 255, 255)  # Yellow for the count text\n",
    "\n",
    "# Dummy callback function for the trackbar (required by OpenCV)\n",
    "def on_trackbar(val):\n",
    "    pass\n",
    "\n",
    "def main():\n",
    "    # GPU VERIFICATION\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device(\"cuda\")\n",
    "        print(f\"GPU is available. Using device: {torch.cuda.get_device_name(0)}\")\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "        print(\"GPU not available. Using CPU.\")\n",
    "\n",
    "    # 1. Load the pretrained YOLOv8 model and move it to the selected device\n",
    "    print(\"Loading model...\")\n",
    "    # The model will be automatically sent to the 'device' (GPU or CPU)\n",
    "    model = YOLO(\"yolov8n.pt\") # Using the nano version for complete performance\n",
    "    model.to(device) # Explicitly send the model to the GPU\n",
    "    class_names = model.names\n",
    "    print(\"Model loaded successfully.\")\n",
    "\n",
    "    # 2. Initialize webcam capture\n",
    "    cap = cv2.VideoCapture(WEBCAM_INDEX)\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Could not open webcam.\")\n",
    "        return\n",
    "\n",
    "    # BONUS FEATURE SETUP: Interactive Confidence Trackbar\n",
    "    cv2.namedWindow(WINDOW_NAME)\n",
    "    # The trackbar value is an integer from 0 to 100. We'll divide by 100.\n",
    "    initial_confidence = 50 # Corresponds to 0.5\n",
    "    cv2.createTrackbar(\"Confidence\", WINDOW_NAME, initial_confidence, 100, on_trackbar)\n",
    "\n",
    "    # Variables for FPS calculation\n",
    "    prev_frame_time = 0\n",
    "\n",
    "    while True:\n",
    "        # 3. Read a frame from the webcam\n",
    "        success, frame = cap.read()\n",
    "        if not success:\n",
    "            print(\"Error: Failed to capture frame.\")\n",
    "            break\n",
    "\n",
    "        # Get the current confidence threshold from the trackbar\n",
    "        confidence_threshold = cv2.getTrackbarPos(\"Confidence\", WINDOW_NAME) / 100.0\n",
    "\n",
    "        # BONUS FEATURE SETUP: Object Counter\n",
    "        # Initialize a dictionary to store the count of each object class for the current frame\n",
    "        object_counts = defaultdict(int)\n",
    "\n",
    "        # 4. Perform inference on the frame\n",
    "        # The model will process the frame on the GPU\n",
    "        results = model(frame, stream=True, verbose=False)\n",
    "\n",
    "        # 5. Process and display detection results\n",
    "        for r in results:\n",
    "            boxes = r.boxes\n",
    "            for box in boxes:\n",
    "                confidence = box.conf[0]\n",
    "                # Filter detections by the real-time confidence threshold\n",
    "                if confidence < confidence_threshold:\n",
    "                    continue\n",
    "\n",
    "                # Get class name\n",
    "                cls_index = int(box.cls[0])\n",
    "                cls_name = class_names[cls_index]\n",
    "\n",
    "                # Increment the count for the detected class\n",
    "                object_counts[cls_name] += 1\n",
    "\n",
    "                # Get bounding box coordinates and draw them\n",
    "                x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "                label = f\"{cls_name}: {confidence:.2f}\"\n",
    "                cv2.rectangle(frame, (x1, y1), (x2, y2), BOX_COLOR, BOX_THICKNESS)\n",
    "                cv2.putText(frame, label, (x1, y1 - 10), FONT, FONT_SCALE, FONT_COLOR, BOX_THICKNESS)\n",
    "\n",
    "        # 6. Calculate and display FPS\n",
    "        new_frame_time = time.time()\n",
    "        if prev_frame_time > 0:\n",
    "            fps = 1 / (new_frame_time - prev_frame_time)\n",
    "            cv2.putText(frame, f\"FPS: {int(fps)}\", (10, 30), FONT, FONT_SCALE, (0, 0, 255), BOX_THICKNESS)\n",
    "        prev_frame_time = new_frame_time\n",
    "\n",
    "        # BONUS FEATURE DISPLAY: Object Counts\n",
    "        # Display the counts on the top-right of the screen\n",
    "        y_offset = 40\n",
    "        # Sort items for a consistent display order\n",
    "        for obj_name, count in sorted(object_counts.items()):\n",
    "            count_text = f\"{obj_name}: {count}\"\n",
    "            cv2.putText(frame, count_text, (frame.shape[1] - 180, y_offset), FONT, FONT_SCALE, COUNT_COLOR, BOX_THICKNESS)\n",
    "            y_offset += 30 # Move down for the next line\n",
    "\n",
    "        # 7. Display the final frame in the named window\n",
    "        cv2.imshow(WINDOW_NAME, frame)\n",
    "\n",
    "        # 8. Exit loop on 'q' key press\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    # 9. Release resources\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bina1task_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
